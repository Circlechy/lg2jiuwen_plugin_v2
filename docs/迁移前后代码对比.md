# LangGraph vs openJiuwen 伪代码对比

## 1. LangGraph Agent 伪代码

```python
# ==================== 工具 ====================
@tool
def calculator(expression: str) -> str: ...

tool_map = {"Calculator": calculator, "Weather": weather}

# ==================== 节点函数 ====================
def think_node(state: AgentState) -> dict:
    response = llm.invoke(messages).content      # 同步调用
    loop_count = state.get("loop_count", 0) + 1  # 读取状态
    return {"thought": thought, "selected_tool": tool, "loop_count": loop_count}

def select_tool_node(state: AgentState) -> dict:
    result = tool_map[state["selected_tool"]].invoke(state["tool_input"])  # 工具调用
    return {"result": result}

def judge_node(state: AgentState) -> dict:
    is_end = llm.invoke(messages)  # 判断是否结束
    return {"is_end": is_end}

# ==================== 路由 ====================
def judge_router(state: AgentState) -> str:
    if state.get("is_end"): return END
    if state.get("loop_count") >= 3: return END
    return "think"

# ==================== 构图 ====================
graph = StateGraph(AgentState)
graph.add_node("think", think_node)
graph.add_node("select_tool", select_tool_node)
graph.add_node("judge", judge_node)
graph.set_entry_point("think")
graph.add_edge("think", "select_tool")
graph.add_edge("select_tool", "judge")
graph.add_conditional_edges("judge", judge_router, {"end": END, "think": "think"})
app = graph.compile()

# ==================== 运行 ====================
result = app.invoke({"input": "100+200=?", "is_end": False, "loop_count": 0})
```

---

## 2. openJiuwen Agent 伪代码

```python
# ==================== 工具 ====================
@tool(name="calculator", params=[Param(name="expression", type="string")])
def calculator(expression: str) -> str: ...

tool_map = {"Calculator": calculator, "Weather": weather}

def invoke_tool(name, arg):
    return tool_map[name].invoke(inputs={tool_map[name].params[0].name: arg})

# ==================== 组件类 ====================
class ThinkComp(WorkflowComponent, ComponentExecutable):
    async def invoke(self, inputs, runtime, context) -> Output:
        response = (await self._llm.ainvoke(model_name, messages)).content  # 异步调用
        loop_count = (runtime.get_global_state("loop_count") or 0) + 1      # 全局状态
        runtime.update_global_state({"loop_count": loop_count})             # 更新全局
        return {"thought": thought, "selected_tool": tool, "loop_count": loop_count}

class SelectToolComp(WorkflowComponent, ComponentExecutable):
    async def invoke(self, inputs, runtime, context) -> Output:
        result = invoke_tool(inputs["selected_tool"], inputs["tool_input"])  # 工具调用
        return {"result": result}

class JudgeComp(WorkflowComponent, ComponentExecutable):
    async def invoke(self, inputs, runtime, context) -> Output:
        is_end = await self._llm.ainvoke(...)
        runtime.update_global_state({"is_end": is_end})
        return {"is_end": is_end}

# ==================== 路由 ====================
def judge_router(runtime) -> str:
    if runtime.get_global_state("judge.is_end"): return "end"   # 上游输出带前缀
    if runtime.get_global_state("loop_count") >= 3: return "end" # 全局状态
    return "think"

# ==================== 构建工作流 ====================
workflow = Workflow()
workflow.set_start_comp("start", Start(), inputs_schema={"input": "${input}", ...})
workflow.add_workflow_comp("think", ThinkComp(),inputs_schema={"input": "${start.input}"})
workflow.add_workflow_comp("select_tool", SelectToolComp(),inputs_schema={"selected_tool": "${think.selected_tool}"})  # 显式数据流
workflow.add_workflow_comp("judge", JudgeComp(),inputs_schema={"result": "${select_tool.result}"})
workflow.set_end_comp("end", End(), inputs_schema={...})
workflow.add_connection("start", "think")
workflow.add_connection("think", "select_tool")
workflow.add_connection("select_tool", "judge")
workflow.add_conditional_connection("judge", judge_router)

# ==================== 运行 ====================
result = await workflow.invoke({"input": "100+200=?", ...}, runtime)  # 异步
```

---

## 3. 核心差异

| 对比项 | LangGraph | openJiuwen |
|--------|-----------|------------|
| **节点** | 函数 | 组件类 |
| **执行** | 同步 | 异步 async/await |
| **状态读取** | `state["key"]` | `inputs["key"]` 或 `runtime.get_global_state("key")` |
| **LLM调用** | `llm.invoke()` | `await self._llm.ainvoke()` |
| **工具调用** | `tool.invoke(arg)` | `tool.invoke(inputs={param: arg})` |
| **数据传递** | 隐式（全局state） | 显式（`inputs_schema: ${node.field}`） |
| **路由访问** | `state.get("key")` | `runtime.get_global_state("node.key")` |
| **结束标记** | `END` | `"end"` |

---

## 4. 目录结构

```
LangGraph                             openJiuwen
───────────────────────────────────────────────────────────
react_agent/                          agent/
├── config.py    # LLM配置            ├── config.py       # LLM配置+全局变量
├── tools.py     # 工具函数           ├── tools.py        # 工具+invoke_tool
├── state.py     # 状态TypedDict      ├── components/     # 组件目录
├── nodes.py     # 所有节点函数       │   ├── think_comp.py
├── router.py    # 路由函数           │   ├── select_tool_comp.py
├── graph.py     # 图构建             │   └── judge_comp.py
└── main.py      # 主入口             ├── routers.py      # 路由函数
                                      ├── workflow.py     # 工作流构建
                                      └── main.py         # 主入口
```

**差异**：openJiuwen 将节点拆分为独立组件文件，无需显式状态类定义。
