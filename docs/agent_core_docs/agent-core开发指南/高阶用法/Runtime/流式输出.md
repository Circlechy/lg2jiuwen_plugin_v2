在openJiuwen框架中，工作流、Agent运行时由`Runtime`核心类实现，该类提供了实时将数据流式输出到工作流或Agent外的能力，使得工作流和Agent场景能够实现高效、实时的数据处理和传递，从而满足高性能和高实时性的应用需求。`Runtime`支持以下两种流式输出场景：

* **工作流流式输出**：在工作流中，大模型组件的token生成和提问器组件的交互过程均支持实时流式输出，且组件运行时的调试与异常信息也可通过流式方式呈现，实现全链路实时监控与问题处理。
* **Agent流式输出**：在Agent中，Agent的思考、规划、执行过程均可通过流式数据实时反馈给用户，利用异步数据传输机制和结构化输出接口，让用户能够实时监控和了解Agent的执行状态和处理逻辑。

工作流和Agent可通过`Runtime`提供的`write_stream`接口或者`write_custom_stream`接口，将实时生成的数据异步放入消息队列中，并通过工作流和Agent的`stream`接口实时消费和处理这些数据，同时支持openJiuwen标准格式`OutputSchema`和用户自定义数据格式`CustomSchema`的结构化输出。

# 工作流流式输出

在工作流场景下，流式输出的实现通常依赖于各组件调用`Runtime`提供的流式输出接口，通过异步生产-消费数据架构来逐步传递实时数据。以下将介绍如何利用`Runtime`的两个流式输出接口，设计并实现具备流式输出功能的工作流。

自定义组件`CustomComponent`，组件输入是思考模式标识，`True`表示开启思考模式，输出标准格式的流式数据；`False`表示关闭思考模式，输出自定义格式的流式数据。

```python
import asyncio

from openjiuwen.core.component.base import WorkflowComponent
from openjiuwen.core.component.end_comp import End
from openjiuwen.core.component.start_comp import Start
from openjiuwen.core.context_engine.base import Context
from openjiuwen.core.graph.executable import Input, Output
from openjiuwen.core.runtime.base import ComponentExecutable
from openjiuwen.core.runtime.runtime import Runtime
from openjiuwen.core.runtime.workflow import WorkflowRuntime
from openjiuwen.core.stream.base import OutputSchema, BaseStreamMode, CustomSchema
from openjiuwen.core.workflow.base import Workflow

class CustomComponent(WorkflowComponent, ComponentExecutable):
    def __init__(self, component_id: str):
        super().__init__()
        self.component_id = component_id

    async def invoke(self, inputs: Input, runtime: Runtime, context: Context) -> Output:
        """根据是否是思考模式输出不同格式的流式数据"""
        think_mode = inputs.get("think_mode", False)
        if think_mode:
            # 标准格式流式输出，数据输入类型为OutputSchema
            await runtime.write_stream(OutputSchema(type="answer", index=0,
                payload=(self.component_id, {"content": f"I am {self.component_id}, please waiting thinking."})))
        else:
            # 自定义格式流式输出，数据输入类型为dict
            await runtime.write_custom_stream(data={"answer": "I will generate a picture for you."})
        return {}
```

搭建基础工作流，将开始组件`start`、自定义组件`stream_out_comp`、结束组件`end`添加到工作流中，并建立三个组件之间的拓扑关系。将流式输出模式设置为标准格式和自定义格式，并在两种场景（思考模式开启、关闭）下执行该工作流：

```python
async def run_workflow(think_mode: bool):
    # 初始化工作流
    workflow = Workflow()

    # 添加开始、结束组件到工作流
    workflow.set_start_comp("start", Start(), inputs_schema={"query": "${user_inputs.query}"})
    workflow.set_end_comp("end", End(),
                          inputs_schema={"query": "${start.query}", "answer": "${stream_out_comp.answer}"})

    # 添加实现直接流式输出的自定义组件
    stream_out_comp = CustomComponent(component_id="stream_out_comp")
    workflow.add_workflow_comp("stream_out_comp", stream_out_comp,
                               inputs_schema={"think_mode": "${user_inputs.think_mode}"})

    # 定义组件连接
    workflow.add_connection("start", "stream_out_comp")
    workflow.add_connection("stream_out_comp", "end")
    # 构造输入、工作流运行时，调用工作流
    inputs = {"user_inputs": {"query": "Help me generate a picture of West Lake.",
                              "think_mode": think_mode}}
    runtime = WorkflowRuntime()

    # 设置流式输出模式为标准格式和自定义格式
    print(f"\n{'=' * 20} think_mode is {think_mode}, begin to run workflow {'=' * 20}\n")
    async for chunk in workflow.stream(inputs, runtime, stream_modes=[BaseStreamMode.OUTPUT, BaseStreamMode.CUSTOM]):
        if isinstance(chunk, OutputSchema):
            print(f"Receive stream chunk (OutputSchema): {chunk}")
        elif isinstance(chunk, CustomSchema):
            print(f"Receive stream chunk (CustomSchema): {chunk}")
        else:
            print(f"Receive stream chunk (CustomSchema): {chunk}")
    print(f"\n{'=' * 21} think_mode is {think_mode}, end to run workflow {'=' * 21}\n")


async def main():
    # 场景1：设置think_mode为True
    await run_workflow(think_mode=True)

    # 场景2：设置think_mode为False
    await run_workflow(think_mode=False)


asyncio.run(main())
```

输出结果为：

```python
==================== think_mode is True, begin to run workflow ====================
Receive stream chunk (OutputSchema): type='answer' index=0 payload=('stream_out_comp', {'content': 'I am stream_out_comp, please waiting thinking.'})
Receive stream chunk (OutputSchema): type='workflow_final' index=0 payload={'output': {'query': 'Help me generate a picture of West Lake.'}}
===================== think_mode is True, end to run workflow =====================

==================== think_mode is False, begin to run workflow ====================
Receive stream chunk (CustomSchema): answer='I will generate a picture for you.'
Receive stream chunk (OutputSchema): type='workflow_final' index=0 payload={'output': {'query': 'Help me generate a picture of West Lake.'}}
===================== think_mode is False, end to run workflow =====================
```

从工作流执行结果可看出：

* 当用户输入`think_mode`为`True`时，自定义组件`stream_out_comp`输出流式数据类型为`OutputSchema`，数据内容为`type='answer' index=0 payload=('stream_out_comp', {'content': 'I am stream_out_comp, please waiting thinking.'})`。
* 当用户输入`think_mode`为`False`时，自定义组件`stream_out_comp`输出流式数据类型为`CustomSchema`，数据内容为`answer='I will generate a picture for you.'`。
* 上述两个场景下，工作流均会输出最终执行结果的流式数据，该流式数据类型为`OutputSchema`，数据内容为`type='workflow_final' index=0 payload={'output': {'query': 'Help me generate a picture of West Lake.'}}`。

# Agent流式输出

在Agent场景下，流式输出的实现通常依赖于Agent的技能模块（如大模型服务、工作流等），通过调用`Runtime`提供的流式输出接口，实现数据的实时、高效传输和处理。以下将介绍如何利用`Runtime`的两个流式输出接口，设计并实现具备流式输出功能的Agent。

为了模拟大模型生成token数据的过程，创建一个`MockModel`类，该类根据思考模式标识，生成一系列不同的token。若思考模式开启，则以标准格式流式输出`["I", "am", "MockModel,", "please", "waiting", "thinking."]`列表中的token；若思考模式关闭，则以自定义格式流式输出`["I", "will", "generate", "a", "picture", "for", "you."]`列表中的token。

```python
import asyncio
from typing import Dict, AsyncIterator, Any

from openjiuwen.agent.config.base import AgentConfig
from openjiuwen.core.agent.agent import BaseAgent
from openjiuwen.core.runtime.runtime import Runtime
from openjiuwen.core.stream.base import OutputSchema, CustomSchema

class MockModel:
    def __init__(self, model_name: str):
        self.model_name = model_name if model_name else "MockModel"

    async def call(self, inputs: Dict, runtime: Runtime):
        """模拟大模型生成token"""
        think_mode = inputs.get("think_mode", False)
        # 模拟异步生成token的过程
        if think_mode:
            # 标准格式流式输出，数据输入类型为OutputSchema
            tokens = ["I", "am", "MockModel,", "please", "waiting", "thinking."]
            index = 0
            for token in tokens:
                await asyncio.sleep(0.1)
                await runtime.write_stream(OutputSchema(type="answer", index=index,
                                                        payload=(self.model_name,
                                                                 {"content": token})))
                index += 1
        else:
            # 自定义格式流式输出，数据输入类型为dict
            tokens = ["I", "will", "generate", "a", "picture", "for", "you."]
            for token in tokens:
                await asyncio.sleep(0.1)
                await runtime.write_custom_stream(data={"answer": token})
```

基于Agent的抽象基类自定义一个Agent，并创建一个默认配置的`MockModel`实例作为该Agent的成员，实现Agent调用`MockModel`流式输出数据的功能：

```python
class CustomAgent(BaseAgent):
    def __init__(self, config=None):
        super().__init__(config)
        self._model = MockModel(model_name="MockModel")

    async def invoke(self, inputs: Dict) -> Dict:
        """invoke"""
        pass

    async def stream(self, inputs: Dict) -> AsyncIterator[Any]:
        """调用mock大模型流式输出数据"""
        session_id = inputs.pop("conversation_id", "default_session")
        # 通过Agent基类中的AgentRuntime获取当前运行时
        runtime = await self._runtime.pre_run(session_id=session_id)

        async def stream_process():
            try:
                # 调用mock的模型，将运行时传入，用于实时记录流式数据
                await self._model.call(inputs, runtime)
            except Exception as ex:
                print(f"Model call error: {ex}")
            finally:
                # 运行时后处理，完成资源清理
                await runtime.post_run()

        # 创建异步生产流式数据的任务
        task = asyncio.create_task(stream_process())
        
        # 实时消费流式数据
        async for chunk in runtime.stream_iterator():
            yield chunk

        try:
            await task
        except Exception as e:
            print(f"CustomAgent stream error： {e}")
```

创建一个自定义Agent实例，并在两种场景（思考模式开启、关闭）下执行：

```python
async def run_agent(think_mode: bool):
    config = AgentConfig()
    config.id = "CustomAgent"
    agent = CustomAgent(config)
    print(f"\n{'=' * 20} think_mode is {think_mode}, begin to run agent {'=' * 20}\n")
    async for chunk in agent.stream({"conversation_id": "mock_session", "think_mode": think_mode}):
        if isinstance(chunk, OutputSchema):
            print(f"Receive stream chunk (OutputSchema): {chunk}")
        elif isinstance(chunk, CustomSchema):
            print(f"Receive stream chunk (CustomSchema): {chunk}")
        else:
            print(f"Receive unsupported stream chunk: {chunk}")
    print(f"\n{'=' * 21} think_mode is {think_mode}, end to run agent {'=' * 21}\n")


async def main():
    # 场景1：设置think_mode为True
    await run_agent(think_mode=True)

    # 场景2：设置think_mode为False
    await run_agent(think_mode=False)


asyncio.run(main())
```

输出结果为：

```python
==================== think_mode is True, begin to run agent ====================
Receive stream chunk (OutputSchema): type='answer' index=0 payload=('MockModel', {'content': 'I'})
Receive stream chunk (OutputSchema): type='answer' index=1 payload=('MockModel', {'content': 'am'})
Receive stream chunk (OutputSchema): type='answer' index=2 payload=('MockModel', {'content': 'MockModel,'})
Receive stream chunk (OutputSchema): type='answer' index=3 payload=('MockModel', {'content': 'please'})
Receive stream chunk (OutputSchema): type='answer' index=4 payload=('MockModel', {'content': 'waiting'})
Receive stream chunk (OutputSchema): type='answer' index=5 payload=('MockModel', {'content': 'thinking.'})
===================== think_mode is True, end to run agent =====================

==================== think_mode is False, begin to run agent ====================
Receive stream chunk (CustomSchema): answer='I'
Receive stream chunk (CustomSchema): answer='will'
Receive stream chunk (CustomSchema): answer='generate'
Receive stream chunk (CustomSchema): answer='a'
Receive stream chunk (CustomSchema): answer='picture'
Receive stream chunk (CustomSchema): answer='for'
Receive stream chunk (CustomSchema): answer='you.'
===================== think_mode is False, end to run agent =====================
```

从Agent执行结果可看出：

* 当用户输入`think_mode`为`True`时，Agent输出流式数据类型为`OutputSchema`，输出token数据内容与模拟的一致，即`["I", "am", "MockModel,", "please", "waiting", "thinking."]`列表中的token。
* 当用户输入`think_mode`为`False`时，Agent输出流式数据类型为`CustomSchema`，输出token数据内容与模拟的一致，即`["I", "will", "generate", "a", "picture", "for", "you."]`列表中的token。
