在openJiuwen框架中，工作流由`Workflow`类型实现，配置完成的`Workflow`实例为可执行状态，可通过`invoke`方法进行调用。在需要实时输出的场景下，还支持通过`stream`方法实现流式调用。工作流执行过程中，各个工作流组件所需要的状态数据和框架功能由工作流运行时`WorkflowRuntime`提供，其作用范围为一次工作流的调用过程。

创建与执行工作流的基本步骤如下：

1. 创建工作流：新建工作流实例并初始化，注册组件到工作流并连接组件。
2. 执行工作流：每次执行创建工作流运行时，基于用户输入和工作流运行时调用工作流。

# 创建工作流

## 初始化工作流

新建工作流实例并初始化，目前支持通过默认配置创建与通过自定义配置创建2种方式。

### 通过默认配置创建

直接通过新建一个工作流对象，即可快速创建一个默认配置的工作流：

```python
from openjiuwen.core.workflow.base import Workflow

workflow = Workflow()
```

### 通过自定义配置创建

在一些复杂的工作流构建场景下，在创建`Workflow`工作流时，可指定工作流的配置信息。工作流的配置信息由`WorkflowConfig`表示，其包含了一个工作流的完整信息。`WorkflowConfig`支持默认空构造和指定工作流ID、名称、版本信息构造方式。

```python
from openjiuwen.core.workflow.base import Workflow
from openjiuwen.core.workflow.workflow_config import WorkflowConfig, WorkflowMetadata

# 新建一个默认的空配置，组件与边默认为空
empty_workflow_config = WorkflowConfig()
workflow_with_empty_config = Workflow(workflow_config=empty_workflow_config)

# 新建一个工作流配置包含工作流的ID、名称、版本信息，组件与边默认为空
name = "test_workflow"
id = "test_workflow_id"
version = "1.0.0"
workflow_config = WorkflowConfig(metadata=WorkflowMetadata(name=name, id=id, version=version))
workflow = Workflow(workflow_config=workflow_config)
```

## 注册组件到工作流

工作流必须包含起始组件和结束组件，其余组件可选用预置组件，也可使用自定义组件。将组件注册到工作流时，`inputs_schema`通常使用引用表达式，其结构为`${<前序组件ID>.<输出值ID>}`，前序组件ID是注册到工作流时用户设定的ID名称，不能引用不存在的组件。

### 开始组件

通过`set_start_comp`方法注册内置`Start`组件到工作流，设置组件ID是`start`，开始组件输入通过`${query}`读取工作流调用时的用户输入，后序组件可通过`${start.query}` 获取start组件的输出。更多关于Start组件的配置请参见[开始组件](./使用组件/使用预置组件.md#开始组件)章节。

```python
from openjiuwen.core.component.start_comp import Start
from openjiuwen.core.workflow.base import Workflow

workflow = Workflow()
workflow.set_start_comp("start", Start(), inputs_schema={"query": "${query}"})
```

### 业务组件

这里以实现中译英功能的大模型组件为例，通过`add_workflow_comp`方法注册`LLMComponent`组件到工作流。这里大模型组件的前序组件是start，因此可通过`${start.query}`方式从start组件获取输入，在大模型组件的`output_config`中配置了输出格式为`"query": {"type": "string", "description": "改写后的query", "required": True}`，后续组件也可通过`${llm.query}`获取大模型组件输出。更多关于LLM组件的配置请参见[大模型组件](./使用组件/使用预置组件.md#大模型组件)章节。

```python
import os
from datetime import datetime

from openjiuwen.core.component.llm_comp import LLMComponent, LLMCompConfig
from openjiuwen.core.component.common.configs.model_config import ModelConfig
from openjiuwen.core.utils.llm.base import BaseModelInfo

API_BASE = os.getenv("API_BASE", "https://api.openai.com/v1")
API_KEY = os.getenv("API_KEY", "sk-fake")
MODEL_NAME = os.getenv("MODEL_NAME", "")
MODEL_PROVIDER = os.getenv("MODEL_PROVIDER", "")

SYSTEM_PROMPT_TEMPLATE = "你是一个query改写的AI助手。今天的日期是{}。"

def _create_model_config() -> ModelConfig:
    """根据环境变量构造模型配置。"""
    return ModelConfig(
        model_provider=MODEL_PROVIDER,
        model_info=BaseModelInfo(
            model=MODEL_NAME,
            api_base=API_BASE,
            api_key=API_KEY,
            temperature=0.7,
            top_p=0.9,
            timeout=120,  # 增加超时时间到120秒，避免网络问题
        ),
    )

def build_current_date():
    current_datetime = datetime.now()
    return current_datetime.strftime("%Y-%m-%d")

def _create_llm_component() -> LLMComponent:
    """创建 LLM 组件，仅用于抽取结构化字段（location/date）。"""
    model_config = _create_model_config()
    current_date = build_current_date()
    user_prompt = ("\n原始query为：{{query}}\n\n帮我改写原始query，要求：\n"
                   "1. 改为英文；\n"
                   "2. 改写后的query必须包含当前的日期，默认日期为今天；\n"
                   "3. 日期为YYYY-MM-DD格式。")
    config = LLMCompConfig(
        model=model_config,
        template_content=[{"role": "user", "content": SYSTEM_PROMPT_TEMPLATE.format(current_date) + user_prompt}],
        response_format={"type": "text"},
        output_config={
            "query": {"type": "string", "description": "改写后的query", "required": True}
        },
    )
    return LLMComponent(config)

llm = _create_llm_component()

# 注册大模型组件到工作流
workflow.add_workflow_comp("llm", llm, inputs_schema={"query": "${start.query}"})
```

### 结束组件

通过`set_end_comp`方法注册指定输出模板为`{"responseTemplate": "结果:{{final_output}}"}`的`End`组件到工作流，设置组件ID是"end"。End组件可通过`${llm.query}`方式从已执行的LLM组件获取输入。更多关于End组件的配置请参见[结束组件](./使用组件/使用预置组件.md#结束组件)章节。

```python
from openjiuwen.core.component.end_comp import End
# 创建End组件（指定输出模板）
end = End({"responseTemplate": "结果:{{final_output}}"})

# 注册End组件到工作流（批输出模式）
workflow.set_end_comp("end", end, inputs_schema={"final_output": "${llm.query}"})
```

## 连接组件

在工作流中，连接代表组件之间的依赖关系和执行路径，本质上是一条有向连接，用于定义任务的先后顺序或数据传递方向。所有连接均为单向连接，确保流程按预设路径执行，且支持条件判断以实现动态分支。需要注意的是，在部分需要基于组件逻辑输出实现下一个组件动态跳转的场景，组件之间不一定需要建立显式的连接关系。

### 普通连接

普通连接是工作流中最基础的连接形式，它仅表示两个组件之间的直接依赖或顺序关系，无额外条件约束。用于实现线性或简单的任务流转，确保前驱节点完成后自动触发后继组件。通过`workflow.add_connection()`方法创建普通连接，第一个参数是源组件ID，第二个参数是目标组件ID，执行顺序严格按照连接的定义从左到右依次执行。

```python
# 添加普通连接：从"start"组件指向"llm"
workflow.add_connection("start", "llm")

# 添加普通连接：从"llm"指向"end"
workflow.add_connection("llm", "end")
```

### 条件连接

条件连接表示组件间的连接上有条件判断，条件判断的结果决定了目标组件的选择，用于根据特定条件选择不同的执行路径，实现工作流的动态分支。通过`workflow.add_conditional_connection()`方法创建条件连接，第一个参数是源组件ID，第二个参数是条件判断函数，可接收当前的状态变量进行判断并返回目标组件ID。

```python
from openjiuwen.core.runtime.runtime import Runtime

# 从Runtime中获取"start"组件输出的"query"字段值，基于query的大小决定下一执行的组件
def router(runtime: Runtime):
    num = runtime.get_global_state("start.query")
    if num == 0:
        return "a"
    elif num == 1:
        return "b"
    else:
        return "a"

# 增加条件连接 start -> a/b
workflow.add_conditional_connection("start", router=router)
# a -> end
workflow.add_connection("a", "end")
# b -> end
workflow.add_connection("b", "end")
```

条件连接通常在以下几种场景使用：

* 静态分支：大多数场景，明确某个组件后下一个可选择的组件范围，且明确每个分支可执行的条件。
* 回环条件：在一些特定的工作流模式中（例如ReAct），需要实现向回跳转和部分工作流路径循环执行的能力。
* 动态跳转：用户在构造工作流时，根据运行时状态数据动态指定跳转分支。

**静态分支**

在构造图时已确定所有可能的分支路径，通过条件判断选择其中一条执行。

```python
from openjiuwen.core.runtime.runtime import Runtime

def router(runtime: Runtime):
    if runtime.get_global_state("start.value") < 1:
        return "a"
    else:
        return "b"

workflow.add_conditional_connection("start", router=router)
# a -> end
workflow.add_connection("a", "end")
# b -> end
workflow.add_connection("b", "end")
```

**回环条件**

条件连接可指向工作流之前的节点，但使用时要小心，避免造成死循环。

```python
from openjiuwen.core.runtime.runtime import Runtime

def router(runtime: Runtime):
    if runtime.get_global_state("start.value") < 1:
        return "a"
    else:
        return "b"

# start -> a
workflow.add_connection("start", "a")
# a -> router, router->a/b
workflow.add_conditional_connection("a", router=router)
# b -> end
workflow.add_connection("b", "end")
```

**动态跳转**

条件连接可动态跳转到工作流中的其他节点。当`start.value`为a时，跳转到a节点；当 `start.value`为b时，跳转到b节点。

```python
from openjiuwen.core.runtime.runtime import Runtime

def router(runtime: Runtime):
    return runtime.get_global_state("start.value")

workflow.add_conditional_connection("start", router=router)
# a -> end
workflow.add_connection("a", "end")
# b -> end
workflow.add_connection("b", "end")

```

### 流式连接

openJiuwen框架在构建工作流时，也为支持流式输出处理的组件提供了流式连接的能力，这种连接方式允许相邻的两个组件之间传递流式变量。通过`Workflow.add_stream_connection`方法创建条件连接，第一个参数是输出流式消息的生产者组件ID，对应组件需实现`stream`接口或`transform`接口，第二参数是接受流式输入消息的消费者组件ID，对应组件需实现`transform`或`collect`接口。此外，注册消费者组件时，需要为流式连接指定单独的Schema定义`stream_inputs_schema`，使用方式与`inputs_schema`一致。以大模型组件和结束组件之间的流式连接为例，其他场景下组件间流式连接的使用方式相同：

```python
# 注册end组件时，指定流式连接输入定义stream_inputs_schema
workflow.set_end_comp("end_stream", end, stream_inputs_schema={"data": "${llm.output}"})
# 添加流式连接：从"llm"指向"end"，其中大模型组件默认实现了`stream`接口，end组件默认实现了`transform`和`collect`接口
workflow.add_stream_connection("llm", "end_stream")
```

从工作流的层面看，为了实现LLM组件流式消息的实时流出，通常推荐在注册结束组件时指定`response_mode="streaming"`来开启结束组件的流式输出，并使用`workflow.stream`的流式输出调用方式对结束组件的流输出结果进行处理，从而得到工作流的流输出结果。

```python
import asyncio

from openjiuwen.core.runtime.workflow import WorkflowRuntime
from openjiuwen.core.stream.base import BaseStreamMode
# 注册end组件时，指定流式连接输入定义stream_inputs_schema，并指定`response_mode="streaming"`来开启流式输出
workflow.set_end_comp("end_stream", end, stream_inputs_schema={"data": "${llm.output}"}, response_mode="streaming")
# 添加流式连接：从"llm"指向"end"，其中大模型组件默认实现了`stream`接口，end组件默认实现了`transform`和`collect`接口
workflow.add_stream_connection("llm", "end_stream")

# 采用workflow.stream的流式输出调用方式，会调用end组件的【`transform`接口】
async def run_stream():
    async for chunk in workflow.stream(
        {"query": "查询上海的天气"},
        WorkflowRuntime(),
        stream_modes=[BaseStreamMode.OUTPUT]
    ):
        print(chunk)

# 使用 asyncio.run 执行异步函数
if __name__ == "__main__":
    asyncio.run(run_stream())
```

# 执行工作流

## 创建工作流运行时

WorkflowRuntime用于管理工作流的上下文信息，封装了工作流执行过程中所需的配置、状态等内容。

```python
from openjiuwen.core.runtime.workflow import WorkflowRuntime

runtime = WorkflowRuntime()
```

创建`WorkflowRuntime`时，可指定当前请求的会话ID用于跟踪多轮对话的场景，不设置的情况，默认使用临时生成的UUID：

```python
session_id = "test_session"

runtime = WorkflowRuntime(session_id=session_id)
```

## 调用工作流

在一般情况下，Agent工作流执行过程的时延主要分布在大模型服务的访问和外部工具的API调用上。因此，从性能和效率的角度出发，openJiuwen框架默认仅支持异步上下文环境下的调用（基于Python的`asyncio`框架）。若用户希望在同步环境下调用工作流，可使用Python中常用的同步调用异步函数的方法实现，例如：`asyncio.run()`。

工作流支持两种调用方式：

* `invoke`：指一次性处理完整批次数据的工作流执行方式。它接收一组完整数据作为输入，经过工作流处理后，一次性返回完整的处理结果。这种模式适用于数据量固定、处理结果需要完整呈现的场景，例如数据分析、报表生成等场景。
* `stream`：指工作流按照数据流的方式逐步处理数据的工作流执行方式。它接收输入数据流，然后逐步处理并返回中间结果，适用于需要实时响应或逐步处理的场景，例如大模型超长文本生成场景。

### invoke

基于上述的翻译工作流，输入`"查询上海的天气"`和`WorkflowRuntime`，调用`invoke`方法并打印输出结果：

```python
import asyncio

result = asyncio.run(workflow.invoke({"query": "查询上海的天气"}, runtime))
print(f"{result}")
```

输出结果如下：

```python
{"responseContent": "结果:Check the weather in Shanghai on 2025-08-22"}
```

### stream

通过`stream`执行工作流后会返回一个异步生成器，遍历生成器获取的每个消息为一个`chunk`，每个`chunk`都是处理过程中的一个片段，可能包含部分语义、推理中间状态或最终结果的逐步构建。用户可在收到第一个chunk时立即看到进展，后续不断接收补充内容，直到整个流程结束。

openJiuwen提供了**三种流式输出方式**，提供对于流式信息的定制化输出能力，由于所有流式消息在工作流内部共享输出管道，区分输出模式提高了流式消息的可扩展性：

* BaseStreamMode.OUTPUT：只输出框架定义的标准流式数据，数据为`OutputSchema`类型。
* BaseStreamMode.TRACE：只输出框架定义的调测流式数据，数据为`TraceSchema`类型。
* BaseStreamMode.CUSTOM：只输出用户自定义流式数据，数据为`CustomSchema`类型。

通过参数`stream_modes`指定输出类型，该参数是一个`List`，支持多种模式同时输出。若当前没有指定输出模式，默认所有信息都打印。若指定模式，则只打印指定模式相关的信息。基于上述的翻译工作流为例分别介绍三种模式的输出。

> **说明**
>
> 采用`stream`方式进行输出时，需在注册结束组件时指定`response_mode="streaming"`来开启流式输出，并通过`Workflow.add_stream_connection`方法将结束组件与前序组件进行流式连接。

#### BaseStreamMode.OUTPUT

在`workflow.stream`方法中，指定`stream_modes=[BaseStreamMode.OUTPUT]`，表示只输出框架定义的标准流式数据：

```python
# 模拟执行一个关于天气查询的工作流
async for chunk in workflow.stream({"query": "查询上海的天气"}, runtime, stream_modes=[BaseStreamMode.OUTPUT]):
    print(chunk)
```

输出数据类型为`OutputSchema`类型，输出结果如下：

```python
OutputSchema(type = 'end node stream', index = 0, payload = {'answer': '结果:'}),
OutputSchema(type = 'end node stream', index = 1, payload ={ 'answer': 'Check the weather in Shanghai on 2025-08-22' })
```

#### BaseStreamMode.TRACE

在`workflow.stream`方法中，指定`stream_modes=[BaseStreamMode.TRACE]`，表示只输出框架定义的调测流式数据：

```python
# 模拟执行一个关于天气查询的工作流
async for chunk in workflow.stream({"query": "查询上海的天气"}, runtime, stream_modes=[BaseStreamMode.TRACE]):
    print(chunk)
```

输出数据类型为`TraceSchema`类型，输出如下（截取结束节点的调测输出）：

```python
...
# 组件的调测开始事件帧
TraceSchema(type = 'tracer_workflow', payload = {
    'traceId': '86b76988-5549-482b-8401-444b2621641e',
    'startTime': datetime.datetime(2025, 8, 22, 14, 39, 9, 678133),
    'inputs': {
    'final_output': 'Check the weather in Shanghai on 2025-08-22',
    },
    'invokeId': 'end',
    'parentInvokeId': 'llm',
    'executionId': '86b76988-5549-482b-8401-444b2621641e',
    'componentId': 'end',
    'componentName': '',
    'componentType': 'llm_component',
    'status': 'start',
    'parentNodeId': ''
})
# 组件的调测结束事件帧
TraceSchema(type = 'tracer_workflow', payload = {
    'traceId': '86b76988-5549-482b-8401-444b2621641e',
    'startTime': datetime.datetime(2025, 8, 22, 14, 39, 9, 678133),
    'endTime': datetime.datetime(2025, 8, 22, 14, 39, 9, 679167),
    'inputs': {
    'final_output': 'Check the weather in Shanghai on 2025-08-22',
    },
    'outputs': {
    'responseContent': '结果:Check the weather in Shanghai on 2025-08-22'
    },
    'invokeId': 'end',
    'parentInvokeId': 'llm',
    'executionId': '86b76988-5549-482b-8401-444b2621641e',
    'componentId': 'end',
    'componentName': '',
    'componentType': 'llm_component',
    'status': 'finish',
    'parentNodeId': '',
    'streamOutputs': []
})
...
```

#### BaseStreamMode.CUSTOM

为了说明自定义流式数据，将使用到的大模型组件`LLMComponent`中临时添加如下代码：

```python
from openjiuwen.core.component.base import WorkflowComponent
from openjiuwen.core.context_engine.base import Context
from openjiuwen.core.runtime.base import ComponentExecutable, Input, Output
from openjiuwen.core.runtime.runtime import Runtime


class LLMComponent(WorkflowComponent, ComponentExecutable):
    async def invoke(self, inputs: Input, runtime: Runtime, context: Context) -> Output:
        ...
        model_inputs = self._prepare_model_inputs(inputs)
        llm_response = await self._llm.ainvoke(model_inputs)
        # 若response为 {"role": "user", "content": "Check the weather in Shanghai on 2025-08-22"}
        response = llm_response.content
        await runtime.write_custom_stream(**dict(custom_output=response))
        ...
```

在`workflow.stream`方法中，指定`stream_modes=[BaseStreamMode.CUSTOM]`，表示只输出用户自定义的流式数据：

```python
# 模拟执行一个关于天气查询的工作流
async for chunk in workflow.stream({"query": "查询上海的天气"}, runtime, stream_modes=[BaseStreamMode.CUSTOM]):
    print(chunk)
```

输出数据类型为`CustomSchema`类型，输出如下：

```python
...
# LLM组件自定义输出内容
CustomSchema(custom_output = 'Check the weather in Shanghai on 2025-08-22')
...
